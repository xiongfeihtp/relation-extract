关系推断特征抽取
一般特征：
(1)	整体词袋特征(bow)：特征维数（关键词词袋大小），若关系中某一关键词出现，则在该词特征位置1。
(2)	局部词袋特征(spanbow)：特征维数（关键词词袋大小*3），将整个关系句划分为三部分，分别为（关系句首位置-实体A出现位置）、（实体A结束位置-实体B出现位置）、（实体B结束位置-关系句尾位置），分别作词袋特征抽取。
(3)	句中字符距离特征(distance)：特征维数（1维），实体A与实体B在关系句中的字符距离。
(4)	并列关系特征(whetherparallel)：特征维数（2维），实体A与实体B是否存在并列关系，设置规则，第一维查看实体A与实体B之间是否存在并列关系连接词，如“和”、“与”、顿号等。第二维查看句子整体出现顿号的次数是否大于2。
(5)	实体名称特征(entityname)：特征维数（3维），分别是实体A名字中是否出现“银行”，实体B名字中是否出现“银行”，实体A和实体B中是否同时出现“银行”。
依赖树特征：（对关系句进行依赖树结构解析，使用Hanlp的CRF Parser）
（6）依赖距离特征(dependencyDis)：特征维数（1维），实体A与实体B在依赖树上的距离。*实验验证，该特征不起什么作用。
（7）POS TAG特征(postag)：特征维数（POSTAG标签词袋大小），依赖树上包含实体A和实体B路径上POSTAG出现情况，若该POSTAG标签出现，则该位特征置1。
（8）CPOS TAG特征(cpostag)：特征维数（CPOSTAG标签词袋大小），抽取方式与上相同。*实验验证，该特征不起什么作用。
（9）依赖树结构词袋特征(dependencyBOW)：特征维数（关键词词袋大小），在依赖树中包含实体A和实体B的子路径中作词袋特征抽取。
(10)依赖树相邻节点关系特征(subpathrelation)：特征维数（关系词袋大小），在依赖树中包含实体A和实体B的子路径中作关系词袋特征抽取。关系词有如：时态依存、介词依存、核心成分等。
（11）依赖树实体关系特征(entityrelation)：特征维数（4维），实体A是否为实体B的父节点，实体B是否为实体A的父节点，实体A是否为实体B的子节点，实体B是否为实体A的子节点。

运行示例(服务器5号机)：cd /data/crli/RelationClassification
sh feature.sh
基于RNN的关系推断模型：
将基于bAbI阅读理解任务的那个RNN模型框架移到了咱们的实体关系推断任务上来。先简要介绍一下bAbI这个任务，它的数据形式是这样的：

1 John travelled to the hallway.
2 Mary journeyed to the bathroom.
3 Where is John? hallway	1

在这个例子中，前两行是文章内容，第三行是问题、答案以及答案所在文章的行号。整个模型是先将文章和问题转换成词向量形式，再对问题进行RNN编码，将编码结果与问题的embedding进行拼接，再将拼接结果进行另一个RNN编码，最终将该编码结果与答案词表作相似度计算，选择相似度最高的答案作为预测输出，这里的答案词表是文章中的所有词。
整个模型如下图：


而到了咱们中文的关系推断任务上，我将关系句作为文章，将实体1和实体2作为问题，答案就是关系标签。如下：
文章：去年8月,中国宝安集团通过发行股份的方式增持子公司贝特瑞股份至89.93%
问题：中国宝安集团	贝特瑞
答案：1（对应从属关系）
我是对问题和句子进行了字向量表示，带入到上述中模型。最终，在正则数据集上能达到88%的预测准确率，在非正则数据集上仅能达到44%的预测准确率。

运行示例（五号机）：cd /data/crli/relationRNN
python relation_rnn.py

基于双向LSTM关系推断模型
在上述模型的基础上加入了词向量信息，并且对问题和文章均分别作了LSTM编码。具体细节操作为，
（1）	首先对关系句作了分词处理，读取数据时直接读取的是关系句的分词列表。
（2）	引入了预处理的词向量信息，若句子中的词存在预处理的词向量表中，则用预处理好的词向量表示该词向量。其余词的词向量均随机初始化处理。
（3）	对文章句和问题句的词向量表示进行双向LSTM编码，得到结果分别为HWd,HWq。
（4）	对问题句的字符向量进行双向LSTM编码，然后再做vecRepeat处理，将句子长度拉伸到与文章句表示一致。得到结果HCq。
（5）	将文章句表示ECd与HCq做联接处理，concate(ECd,HCq)，得到结果C。
（6）	将结果C输入到另一个双向LSTM进行编码，得到结果HC。
（7）	将HC,HWd,HWq进行联接处理，得到结果H。
（8）	对结果H进行带入到全接连层，进行线性变换，将维数降到标签维数大小。再求softmax,输出概率最大的标签索引。
模型框架如下：

运行示例（五号机）：cd /data/crli/relationRNN
python relation_bilstm.py